List of interesting papers, mostly in ML and CV area.

### Intriguing properties of NN:
#### 2020:
- Can You Trust Your Modelâ€™s Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift, Ovadia et. al, NeurIPS 2019, [[arXiv ](https://arxiv.org/pdf/1906.02530.pdf)]
- Exploring Randomly Wired Neural Networks for Image Recognition, Xie et. al, [[arXiv](https://arxiv.org/pdf/1904.01569.pdf)]


#### 2019:
- The lottery ticket hypothesis: finding sparse, trainable neural networks, Frankle & Carbin, ICLR 2019, [[arXiv](https://arxiv.org/pdf/1803.03635.pdf)]
- Benchmarking Neural Network Robustness to Common Corruptions and Perturbations, Hendrycks et. al, ICLR 2019, [[arXiv](https://arxiv.org/pdf/1903.12261.pdf)]
- Natural Adversarial Examples, D. Hendrycks et. al, [[arXiv](https://arxiv.org/pdf/1907.07174.pdf)] 
- Weight Agnostic Neural Networks, Gaiger & Ha, NeurIPS 2019, [[arXiv](https://arxiv.org/pdf/1906.04358.pdf)]. Architecture search for randomly!! initialized neural networks which can perform reasonably well simple reinforcement learning and classifications tasks.

#### 2018:
- ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness, Geirhos et. al, ICLR 2019, [[arXiv](https://arxiv.org/pdf/1811.12231.pdf)]
- Rethinking ImageNet Pre-Training, He et. al, ICCV 2019, [[arXiv](http://openaccess.thecvf.com/content_ICCV_2019/papers/He_Rethinking_ImageNet_Pre-Training_ICCV_2019_paper.pdf)]. They show that ImageNet pretraining is not as crucial as we thought.
- Same-different problems strain convolutional neural networks, Ricci et. al,  [[arXiv](https://arxiv.org/pdf/1802.03390.pdf)]. They show one of the simplest examples of visual problems that current ml algorithms cannot solve.
- Deep Image Prior, Ulyanov et. al, CVPR 2018 [[arXiv](https://arxiv.org/pdf/1711.10925.pdf)]

#### 2015:
- Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images, Nguyen et. al, CVPR 2015, [[arXiv](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf)]

### CV / ML:

#### 2020:
- Self-training with Noisy Student improves ImageNet classification, Xie et. al, [[arXiv](https://arxiv.org/pdf/1911.04252.pdf)]
- PointRend: Image Segmentation as Rendering, Kirillov et. al, [[arXiv](https://arxiv.org/pdf/1912.08193v2.pdf)]. New approach to image segmentation from randomly selected point-wise features, cool stuff.

#### 2019:
- Learning by Cheating, Chen et. al, CoRL 2019, [[arXiv](https://arxiv.org/pdf/1912.12294.pdf)]
- Objects as Points, Zhou et. al, [[arXiv](https://arxiv.org/pdf/1904.07850.pdf)] 

#### 2018:
- Deep Reinforcement Learning that Matters, Henderson et. al, AAAI 2018, [[arXiv](https://arxiv.org/pdf/1709.06560.pdf)]. On reproduction of baselines in RL, they show that random seeds matters can greatly alter the results and many more, nice read.
- A Probabilistic U-Net for Segmentation of Ambiguous Images, Kohl etl al, DeepMind, German Cancer Research Center, NIPS 2019, [[arXiv](https://arxiv.org/pdf/1806.05034.pdf)]
- The Unreasonable Effectiveness of Deep Features as a Perceptual Metric, Zhang et. al, CVPR 2018, [[arXiv](https://arxiv.org/pdf/1801.03924.pdf)]
- Brute-Force Facial Landmark Analysis With A 140,000-Way Classifier, Li et. al, CMU, AAAI 2018, [[arXiv](https://arxiv.org/pdf/1802.01777.pdf)]
- Noise2Noise: Learning Image Restoration without Clean Data, Lehtinen et. al, NVIDIA, ICML 2018 [[arXiv](https://arxiv.org/pdf/1803.04189.pdf)]
- The Unreasonable Effectiveness of Texture Transfer for Single Image Super-resolution, Gondal et. al, CVPR 2018 [[arXiv](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Gondal_The_Unreasonable_Effectiveness_of_Texture_Transfer_for_Single_Image_Super-resolution_ECCVW_2018_paper.pdf)]

#### 2017:
- Discovering Causal Signals in Images, Lopez-Paz et. al, CVPR 2017, [[arXiv](http://openaccess.thecvf.com/content_cvpr_2017/papers/Lopez-Paz_Discovering_Causal_Signals_CVPR_2017_paper.pdf)]


### Other:

- Winner's Curse? On Pace, Progress, and Empirical Rigor, D. Sculley et. al, 2018 [[openReview](Winner's Curse? On Pace, Progress, and Empirical Rigor )]
- Relational inductive biases, deep learning, and graph networks, Battaglia et. al, 2018, [[arXiv](https://arxiv.org/pdf/1806.01261.pdf)]
The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, Marcus 2020, [[arXiv](https://arxiv.org/pdf/2002.06177.pdf)]
- Building machines that learn and think like people, Lake et. al, 2016, [[arXiv](https://arxiv.org/pdf/1604.00289.pdf)]



